{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ashish Shukla cs.ashishshukla@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final production code for API for stackoveflow case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import tensorflow_hub as hub # Version Should be 0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Loaded\n"
     ]
    }
   ],
   "source": [
    "# Loading embeddings data\n",
    "try:\n",
    "    word2vec_titles_array, all_dataframe_without_preprocess_df,  all_data_index_dictionary, embed \n",
    "    print(\"It exists\")\n",
    "except:\n",
    "    word2vec_titles_array = np.load('all_titles_embeddings.npy')\n",
    "    all_dataframe_without_preprocess_df = pd.read_csv('all_dataframe_without_preprocess.csv', usecols=['Title'])\n",
    "    with open('keyword_index_dict.pickle', 'rb') as handle:\n",
    "        all_data_index_dictionary = pickle.load(handle)\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    print(\"All Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm for detecting text\n",
    "def suggest_questions_for_question_title(question_title, k):\n",
    "    \"\"\"\n",
    "    Before calling this function we must load fallowing files\n",
    "        Load Pretrained Embeddings 'all_titles_embeddings.npy' as word2vec_titles_array\n",
    "        Load keyword_index_dict as all_data_index_dictionary\n",
    "        Load all_dataframe_without_preprocess_df['Title']\n",
    "    This function does fallowing tasks\n",
    "        1 - preprocessing of given raw question_title\n",
    "        2 - converting preprocessed question_title into (1, 512) shape numpy vector\n",
    "        3 - extract all keywords from given question_title\n",
    "        4 - get all indices of stored question titles in which at least one of the keyword found using all_data_index_dictionary\n",
    "        5 - take Numpy arrays of titles corresponding to all above selected indices using word2vec_titles_array\n",
    "        6 - Calculate Cosine distance between asked question title numpy array and all above selected numpy arrays\n",
    "        7 - Select k indices corresponding to k minimum cosine distances calculated above\n",
    "        8 - Select k indices from selected indices in step 4 corresponding to k indices of step 7 in sorted order\n",
    "        9 - take k question titles from all_dataframe_without_preprocess_df['Title'] corresponding to k indices of step 8 \n",
    "            and return it as search result. \n",
    "        \n",
    "    \"\"\"\n",
    "   \n",
    "    # question_title is the title of the single question\n",
    "    \n",
    "    document = question_title\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "   \n",
    "    stemmer = WordNetLemmatizer()\n",
    "    data = document\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleancode = re.compile('<code>.*?</code>')\n",
    "    \n",
    "    clean_text = re.sub(cleanr, ' ', data)\n",
    "    clean_text = re.sub(cleancode, ' ', clean_text)\n",
    "    clean_text = re.sub(r'[^A-Za-z]+',' ',clean_text)\n",
    "    clean_text = clean_text.lower()\n",
    "    \n",
    "    striped_html_text = clean_text\n",
    "    words = word_tokenize(str(striped_html_text.lower()))\n",
    "    #Removing all single letter and and stopwords from question except for the letter 'c'\n",
    "    cleaned_document = ' '.join(str(stemmer.lemmatize(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n",
    "    question_title_preprocessed = cleaned_document\n",
    "    \n",
    "    \n",
    "    # embed is the loaded Universal sentence encoder from tensorflow hub    \n",
    "    question_title_vectorized = embed([question_title_preprocessed]).numpy()\n",
    "\n",
    "    keywords_in_question = question_title_preprocessed.split()\n",
    "    \n",
    "    # keyword_index_dict contain keywords as keys and list of index of documents as values\n",
    "    all_indexes = []\n",
    "    for keyword in keywords_in_question:\n",
    "        try:\n",
    "            all_indexes.extend(all_data_index_dictionary[keyword])\n",
    "        except:\n",
    "            pass\n",
    "   \n",
    "    index_questions_keyword = np.array(list(set(all_indexes)))\n",
    "    \n",
    "    \n",
    "    # word2vec_titles_array is the pre loaded array of all vectors\n",
    "    # Select only those questions embeddings array which contain keyword of query question \n",
    "    word2vec_titles_array_selected = word2vec_titles_array[index_questions_keyword]\n",
    "    \n",
    " \n",
    "    \"\"\"\n",
    "    Here all_arrays shape should be (n, d) and\n",
    "    test array shape should be (1, d)\n",
    "    \"\"\"\n",
    "    all_arrays, test_arrays = question_title_vectorized, word2vec_titles_array_selected\n",
    "    \n",
    "    all_cosine_similarity = cosine_similarity(all_arrays, test_arrays)\n",
    "    all_cosine_distances = (1 - all_cosine_similarity).reshape(1, -1)[0]\n",
    "    \n",
    "    # Since we have to select only k minimum distances so there is no need to short the entire array\n",
    "    index_of_least_distances = np.argpartition(all_cosine_distances, k)[:k]\n",
    "    selected_k_cosine_distances =  all_cosine_distances[index_of_least_distances]\n",
    "    \n",
    "    index_of_least_distances_sorted = np.argsort(selected_k_cosine_distances) # 0 to k range\n",
    "    final_index_of_least_distances_sorted = index_of_least_distances[index_of_least_distances_sorted]\n",
    "\n",
    "    index_questions_keyword_similar = index_questions_keyword[final_index_of_least_distances_sorted]\n",
    "    recommendations = all_dataframe_without_preprocess_df.loc[index_questions_keyword_similar]['Title'].values\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query question is:  How to create a linked list in python?\n",
      "Time taken is: \n",
      " 0:00:00.948463\n",
      "Suggestions are: \n",
      "linked list in python\n",
      "Linked Lists Python 2.7\n",
      "circularly linked list in python\n",
      "Python; Linked list and traversing!\n",
      "Concatenate Python Linked List\n",
      "Circular Linked list in python\n",
      "Why Python doesn't have a native Linked List implementation?\n",
      "Python linked list O(1) insert/remove\n",
      "doubly Linked list iterator python\n",
      "single linked list reverse in python\n",
      "Singly Linked List with special methods in python, stuck\n",
      "Does Python use linked lists for lists? Why is inserting slow?\n",
      "Faster way to create a linked list of n-length in Python\n",
      "python linked list evaluation on the node of self\n",
      "How to create a linked list with a given size(java)?\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "query_question = \"How to create a linked list in python?\"\n",
    "print(\"The query question is: \", query_question)\n",
    "\n",
    "start = datetime.now()\n",
    "recommendations = suggest_questions_for_question_title(query_question, 15)\n",
    "\n",
    "print(\"Time taken is: \\n\", datetime.now()-start)\n",
    "\n",
    "print(\"Suggestions are: \")\n",
    "for recom in recommendations:\n",
    "    print(recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query question is:  How to reverse a linked list in C?\n",
      "Time taken is:\n",
      "  0:00:00.774923\n",
      "Suggestions are: \n",
      "How to reverse linked list C++\n",
      "Reversing a singly linked list in C\n",
      "How to reverse a linked list?\n",
      "reverse a linked list?\n",
      "reverse printing of linked list in c\n",
      "Modifying Linked Lists in C++\n",
      "Singly Linked List - C\n",
      "Sort a linked list in C++\n",
      "Reversing a linked list\n",
      "reversing linked list\n",
      "Linked List in C\n",
      "More linked lists in C\n",
      "linked list in C++\n",
      "reverse linked list problem\n",
      "Doubly linked list in C\n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "query_question = \"How to reverse a linked list in C?\"\n",
    "print(\"The query question is: \", query_question)\n",
    "\n",
    "start = datetime.now()\n",
    "recommendations = suggest_questions_for_question_title(query_question, 15)\n",
    "\n",
    "print(\"Time taken is:\\n \", datetime.now()-start)\n",
    "\n",
    "print(\"Suggestions are: \")\n",
    "for recom in recommendations:\n",
    "    print(recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
